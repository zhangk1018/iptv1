import os
import re
import time
import requests
import concurrent.futures
import sys

# ===============================
# é…ç½®åŒº
# ===============================
INPUT_FILE = "live.txt"
OUTPUT_FILE = "livezubo.txt"
CHECK_COUNT = 2
TEST_DURATION = 12

# ç­›é€‰æ ‡å‡†ï¼ˆå¯è‡ªè¡Œè°ƒæ•´ï¼‰
MIN_PEAK_REQUIRED   = 0.80
MIN_STABLE_REQUIRED = 0.40

# é™çº§æ ‡å‡†
FALLBACK_PEAK   = 0.60
FALLBACK_STABLE = 0.25

def get_realtime_speed(url):
    """è¿”å›ï¼šå³°å€¼é€Ÿåº¦, ååŠæ®µå¹³å‡é€Ÿåº¦(è°·åº•å‚è€ƒ), æ•´ä½“å¹³å‡é€Ÿåº¦"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) PotPlayer/23.9.22",
        "Accept": "*/*"
    }
    try:
        start_time = time.time()
        total_size = 0
        speed_samples = []
        last_size = 0
        last_check = start_time

        with requests.get(url, stream=True, timeout=15, headers=headers) as r:
            if r.status_code != 200:
                return 0.0, 0.0, 0.0

            for chunk in r.iter_content(chunk_size=1024*256):
                if chunk:
                    total_size += len(chunk)
                    now = time.time()

                    if now - last_check >= 0.8:
                        interval = now - last_check
                        current_speed = (total_size - last_size) / interval / 1024 / 1024
                        speed_samples.append(current_speed)
                        last_size = total_size
                        last_check = now

                    if now - start_time > TEST_DURATION:
                        break

        duration = time.time() - start_time
        if duration < 3 or total_size == 0:
            return 0.0, 0.0, 0.0

        overall_avg = (total_size / 1024 / 1024) / duration

        if not speed_samples:
            return overall_avg, overall_avg, overall_avg

        peak_speed = max(speed_samples)
        split_idx = max(2, len(speed_samples) * 4 // 10)
        stable_avg = sum(speed_samples[split_idx:]) / len(speed_samples[split_idx:]) if len(speed_samples) > 4 else overall_avg

        return peak_speed, stable_avg, overall_avg

    except Exception:
        return 0.0, 0.0, 0.0


def test_ip_group(ip_port, channels):
    test_targets = [u for n, u in channels if "CCTV1" in n or "CCTV5" in n][:CHECK_COUNT]
    if len(test_targets) < CHECK_COUNT:
        test_targets = [c[1] for c in channels[:CHECK_COUNT]]

    best_peak = 0.0
    best_stable = 0.0
    best_overall = 0.0
    best_url = ""

    for url in test_targets:
        peak, stable, overall = get_realtime_speed(url)
        if (peak > best_peak) or (peak == best_peak and stable > best_stable):
            best_peak = peak
            best_stable = stable
            best_overall = overall
            best_url = url

    timestamp = time.strftime("%H:%M:%S", time.localtime())
    sys.stdout.write(
        f"[{timestamp}] {ip_port:21} â†’ "
        f"å³°å€¼:{best_peak:5.2f}  è°·åº•å‚è€ƒ:{best_stable:5.2f}  æ•´ä½“:{best_overall:5.2f} MB/s   {best_url[:70]}\n"
    )
    sys.stdout.flush()

    return ip_port, best_peak, best_stable, best_overall


def main():
    if not os.path.exists(INPUT_FILE):
        print(f"âš ï¸ è¾“å…¥æ–‡ä»¶ {INPUT_FILE} ä¸å­˜åœ¨ï¼Œè„šæœ¬é€€å‡ºã€‚")
        return

    with open(INPUT_FILE, "r", encoding="utf-8") as f:
        lines = f.readlines()

    ip_groups = {}
    other_info = []
    for line in lines:
        line = line.strip()
        if "," in line and "$" in line:
            name, url_part = line.split(",", 1)
            match = re.search(r'http://(.*?)/', url_part)
            if match:
                ip_port = match.group(1)
                ip_groups.setdefault(ip_port, []).append((name, url_part))
        elif line:
            other_info.append(line)

    print(f"\nğŸš€ å¯åŠ¨ç­›é€‰ | å€™é€‰æœåŠ¡å™¨: {len(ip_groups)} ä¸ª | æµ‹è¯•æ—¶é•¿: {TEST_DURATION}s\n")

    results = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        futures = {executor.submit(test_ip_group, ip, chs): ip for ip, chs in ip_groups.items()}
        for future in concurrent.futures.as_completed(futures):
            ip_port, peak, stable, overall = future.result()
            results[ip_port] = (peak, stable, overall)

    print("\n" + "="*70)

    # ç­›é€‰æœåŠ¡å™¨
    selected_ips = [
        ip for ip, (peak, stable, _) in results.items()
        if peak >= MIN_PEAK_REQUIRED and stable >= MIN_STABLE_REQUIRED
    ]

    final_step = f"å³°å€¼â‰¥{MIN_PEAK_REQUIRED} & è°·åº•â‰¥{MIN_STABLE_REQUIRED}"

    if not selected_ips:
        print("âŒ æ²¡æœ‰å®Œå…¨è¾¾æ ‡æœåŠ¡å™¨ï¼Œè¿›å…¥é™çº§æ¨¡å¼...")
        selected_ips = [
            ip for ip, (peak, stable, _) in results.items()
            if peak >= FALLBACK_PEAK and stable >= FALLBACK_STABLE
        ]
        final_step = f"é™çº§æ¨¡å¼ï¼šå³°å€¼â‰¥{FALLBACK_PEAK} & è°·åº•â‰¥{FALLBACK_STABLE}"

    if not selected_ips:
        best_ip = max(results, key=lambda x: results[x][0])
        selected_ips = [best_ip]
        peak, stable, _ = results[best_ip]
        final_step = f"ä¿åº•æœ€å¿«ï¼šå³°å€¼ {peak:.2f} / è°·åº• {stable:.2f}"

    print(f"âœ… æœ€ç»ˆå…¥é€‰ {len(selected_ips)} ä¸ªæœåŠ¡å™¨ï¼ˆæ ‡å‡†ï¼š{final_step}ï¼‰\n")

    # ===================== è¾“å‡ºéƒ¨åˆ† - å¢åŠ å»é‡ =====================
    try:
        from fofa_fetch import CHANNEL_CATEGORIES
    except ImportError:
        print("âŒ æ— æ³•å¯¼å…¥ CHANNEL_CATEGORIESï¼Œè¯·æ£€æŸ¥ fofa_fetch.py")
        return

    final_output = [l for l in other_info if "#genre#" in l or "æ›´æ–°æ—¶é—´" in l]
    final_output.append("")

    for category, ch_list in CHANNEL_CATEGORIES.items():
        category_added = False

        for std_name in ch_list:
            # ç”¨ dict å­˜å‚¨ url â†’ (peak, stable) ï¼Œå¤©ç„¶å»é‡
            url_info = {}

            for ip in selected_ips:
                for name, url_part in ip_groups.get(ip, []):
                    if name == std_name:
                        peak, stable, _ = results[ip]
                        # å¦‚æœå·²æœ‰ç›¸åŒurlï¼Œå–æ›´å¥½çš„è¯„åˆ†
                        if url_part not in url_info or (peak, stable) > url_info[url_part]:
                            url_info[url_part] = (peak, stable)

            if not url_info:
                continue

            # æŒ‰ (å³°å€¼, è°·åº•) é™åºæ’åº
            sorted_entries = sorted(
                url_info.items(),
                key=lambda x: (x[1][0], x[1][1]),
                reverse=True
            )

            # åªå–æœ€å¥½çš„é‚£ä¸€ä¸ªï¼ˆå·²å»é‡ï¼‰
            if sorted_entries:
                if not category_added:
                    final_output.append(f"{category},#genre#")
                    category_added = True
                
                best_url, _ = sorted_entries[0]
                final_output.append(f"{std_name},{best_url}")

        if category_added:
            final_output.append("")

    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(final_output).rstrip() + "\n")

    print(f"\nğŸ¯ ç­›é€‰å®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_FILE}")
    print(f"   å·²ä¿ç•™ {len(selected_ips)} ä¸ªæœåŠ¡å™¨æºï¼ŒåŒé¢‘é“é“¾æ¥å·²å»é‡")


if __name__ == "__main__":
    main()
