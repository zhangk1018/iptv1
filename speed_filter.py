import os
import re
import time
import requests
import concurrent.futures
import sys
import random

# ===============================
# é…ç½®åŒº
# ===============================
INPUT_FILES = [
    "live.txt",
    "IPTV.txt"
    # å¯ä»¥ç»§ç»­æ·»åŠ æ›´å¤šæ–‡ä»¶ï¼Œä¾‹å¦‚ "backup.txt", "new_sources.txt"
]

OUTPUT_FILE = "livezubo.txt"
CHECK_COUNT = 2
TEST_DURATION = 12

# ä¸¥æ ¼æ¨¡å¼ï¼ˆä¸»åŠ›æ¨èï¼Œæ ¹æ®å®é™…æºæ± å¯è°ƒï¼‰
MIN_PEAK_REQUIRED = 1.10
MIN_STABLE_REQUIRED = 1.03   # è°·åº•å‚è€ƒ â‰¥0.9 æ‰çœŸæ­£ç¨³

# é™çº§æ¨¡å¼
FALLBACK_PEAK = 0.95
FALLBACK_STABLE = 0.75

def get_realtime_speed(url):
    """è¿”å›ï¼šå³°å€¼é€Ÿåº¦, ååŠæ®µå¹³å‡é€Ÿåº¦(è°·åº•å‚è€ƒ), æ•´ä½“å¹³å‡é€Ÿåº¦"""
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) PotPlayer/23.9.22",
        "Accept": "*/*"
    }
    try:
        start_time = time.time()
        total_size = 0
        speed_samples = []
        last_size = 0
        last_check = start_time

        with requests.get(url, stream=True, timeout=15, headers=headers) as r:
            if r.status_code != 200:
                return 0.0, 0.0, 0.0

            for chunk in r.iter_content(chunk_size=1024*256):
                if chunk:
                    total_size += len(chunk)
                    now = time.time()

                    if now - last_check >= 0.8:
                        interval = now - last_check
                        current_speed = (total_size - last_size) / interval / 1024 / 1024
                        speed_samples.append(current_speed)
                        last_size = total_size
                        last_check = now

                    if now - start_time > TEST_DURATION:
                        break

        duration = time.time() - start_time
        if duration < 3 or total_size == 0:
            return 0.0, 0.0, 0.0

        overall_avg = (total_size / 1024 / 1024) / duration

        if not speed_samples:
            return overall_avg, overall_avg, overall_avg

        peak_speed = max(speed_samples)
        split_idx = max(2, len(speed_samples) * 4 // 10)
        stable_avg = sum(speed_samples[split_idx:]) / len(speed_samples[split_idx:]) if len(speed_samples) > 4 else overall_avg

        return peak_speed, stable_avg, overall_avg

    except Exception:
        return 0.0, 0.0, 0.0


def test_ip_group(ip_port, channels):
    keywords = [
        "CCTV4", "CCTV-4", "CCTV-04", "CCTV4ä¸­æ–‡å›½é™…", "CCTV-4ä¸­æ–‡å›½é™…", "ä¸­æ–‡å›½é™…", "CCTV4å›½é™…", "å›½é™…é¢‘é“", "å››å¥—",
        "æ¹–å—å«è§†", "æ¹–å—", "HUNAN", "å¿«ä¹å¤§æœ¬è¥", "èŠ’æœ", "èŠ’æœTV", "é‡‘é¹°", "å«è§†æ¹–å—", "æ¹–å—ä¸€å¥—"
    ]

    test_targets = []
    for name, url in channels:
        upper_name = name.upper()
        if any(kw.upper() in upper_name for kw in keywords):
            test_targets.append(url)

    if len(test_targets) >= CHECK_COUNT:
        test_targets = test_targets[:CHECK_COUNT]
    else:
        remaining = CHECK_COUNT - len(test_targets)
        other_channels = [url for n, url in channels if url not in test_targets]

        if other_channels:
            random_selected = random.sample(other_channels, min(remaining, len(other_channels)))
            test_targets.extend(random_selected)
        else:
            test_targets = [url for _, url in channels][:CHECK_COUNT]

    if not test_targets and channels:
        test_targets = [channels[0][1]]

    best_peak = 0.0
    best_stable = 0.0
    best_overall = 0.0
    best_url = ""

    for url in test_targets:
        peak, stable, overall = get_realtime_speed(url)
        if (peak > best_peak) or (peak == best_peak and stable > best_stable):
            best_peak = peak
            best_stable = stable
            best_overall = overall
            best_url = url

    timestamp = time.strftime("%H:%M:%S", time.localtime())
    sys.stdout.write(
        f"[{timestamp}] {ip_port:21} â†’ "
        f"å³°å€¼:{best_peak:5.2f}  è°·åº•å‚è€ƒ:{best_stable:5.2f}  æ•´ä½“:{best_overall:5.2f} MB/s   æµ‹è¯•ç”¨: {best_url[:70]}\n"
    )
    sys.stdout.flush()

    return ip_port, best_peak, best_stable, best_overall


def main():
    if not INPUT_FILES:
        print("âš ï¸ æ²¡æœ‰é…ç½®ä»»ä½•è¾“å…¥æ–‡ä»¶ï¼Œè„šæœ¬é€€å‡ºã€‚")
        return

    all_lines = []
    for input_file in INPUT_FILES:
        if not os.path.exists(input_file):
            print(f"âš ï¸ è¾“å…¥æ–‡ä»¶ {input_file} ä¸å­˜åœ¨ï¼Œè·³è¿‡ã€‚")
            continue
        with open(input_file, "r", encoding="utf-8") as f:
            lines = f.readlines()
            all_lines.extend(lines)
        print(f"å·²è¯»å– {input_file}ï¼Œå…± {len(lines)} è¡Œ")

    ip_groups = {}
    other_info = []
    for line in all_lines:
        line = line.strip()
        if "," in line and "$" in line:
            name, url_part = line.split(",", 1)
            match = re.search(r'http://(.*?)/', url_part)
            if match:
                ip_port = match.group(1)
                ip_groups.setdefault(ip_port, []).append((name, url_part))
        elif line:
            other_info.append(line)

    print(f"\nğŸš€ å¯åŠ¨ç­›é€‰ | å€™é€‰æœåŠ¡å™¨: {len(ip_groups)} ä¸ª | æµ‹è¯•æ—¶é•¿: {TEST_DURATION}s\n")

    results = {}
    with concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:
        futures = {executor.submit(test_ip_group, ip, chs): ip for ip, chs in ip_groups.items()}
        for future in concurrent.futures.as_completed(futures):
            ip_port, peak, stable, overall = future.result()
            results[ip_port] = (peak, stable, overall)

    print("\n" + "="*70)

    selected_ips = [
        ip for ip, (peak, stable, _) in results.items()
        if peak >= MIN_PEAK_REQUIRED and stable >= MIN_STABLE_REQUIRED
    ]

    final_step = f"å³°å€¼â‰¥{MIN_PEAK_REQUIRED} & è°·åº•â‰¥{MIN_STABLE_REQUIRED}"

    if not selected_ips:
        print("âŒ æ²¡æœ‰å®Œå…¨è¾¾æ ‡æœåŠ¡å™¨ï¼Œè¿›å…¥é™çº§æ¨¡å¼...")
        selected_ips = [
            ip for ip, (peak, stable, _) in results.items()
            if peak >= FALLBACK_PEAK and stable >= FALLBACK_STABLE
        ]
        final_step = f"é™çº§æ¨¡å¼ï¼šå³°å€¼â‰¥{FALLBACK_PEAK} & è°·åº•â‰¥{FALLBACK_STABLE}"

    if not selected_ips:
        best_ip = max(results, key=lambda x: results[x][0])
        selected_ips = [best_ip]
        peak, stable, _ = results[best_ip]
        final_step = f"ä¿åº•æœ€å¿«ï¼šå³°å€¼ {peak:.2f} / è°·åº• {stable:.2f}"

    print(f"âœ… æœ€ç»ˆå…¥é€‰ {len(selected_ips)} ä¸ªæœåŠ¡å™¨ï¼ˆæ ‡å‡†ï¼š{final_step}ï¼‰\n")

    # ===================== è¾“å‡ºæ‰€æœ‰å…¥é€‰æœåŠ¡å™¨çš„å…¨éƒ¨é¢‘é“ï¼ˆä¸é‡ç»„ï¼Œä¸é™ç±»åˆ«ï¼‰ =====================
    final_output = [line for line in other_info if line.strip()]  # ä¿ç•™å¤´éƒ¨ä¿¡æ¯
    final_output.append("")  # åŠ ç©ºè¡Œ

    # æ”¶é›†å…¥é€‰æœåŠ¡å™¨çš„æ‰€æœ‰åŸå§‹é¢‘é“è¡Œ
    all_selected_lines = []
    for ip in selected_ips:
        for name, url_part in ip_groups.get(ip, []):
            all_selected_lines.append(f"{name},{url_part}")

    # å…¨å±€å»é‡æ•´è¡Œï¼ˆé˜²æ­¢æºæ–‡ä»¶æœ¬èº«æœ‰å®Œå…¨ç›¸åŒçš„é‡å¤è¡Œï¼‰
    seen_lines = set()
    unique_lines = []
    for line in all_selected_lines:
        stripped = line.strip()
        if stripped and stripped not in seen_lines:
            seen_lines.add(stripped)
            unique_lines.append(line)

    final_output.extend(unique_lines)

    # å†™æ–‡ä»¶
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        f.write("\n".join(final_output).rstrip() + "\n")

    print(f"\nğŸ¯ ç­›é€‰å®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_FILE}")
    print(f"   å·²ä¿ç•™ {len(selected_ips)} ä¸ªæœåŠ¡å™¨çš„æ‰€æœ‰é¢‘é“ï¼ˆå»é‡åå…± {len(unique_lines)} æ¡å”¯ä¸€è¡Œï¼‰")


if __name__ == "__main__":
    main()
